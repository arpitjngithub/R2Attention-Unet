{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import R2AttU_Net\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # model = R2AttU_Net()\n",
    "# # model = model.to(device)\n",
    "# # sample_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# # # Move the sample input to GPU if the model is on GPU\n",
    "# # sample_input = sample_input.to(device)\n",
    "\n",
    "# # # Forward pass through the model\n",
    "# # output = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sprasad/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of large_images: (42, 1024, 1536, 3)\n",
      "Shape of large_masks: (42, 1024, 1536)\n",
      "Image shape: (310, 1, 256, 256, 3)\n",
      "Mask shape: (310, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from patchify import patchify, unpatchify  # Only to handle large images\n",
    "import random\n",
    "from PIL import Image\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_and_pad_images_from_folder(folder, target_size=(1024, 1536)):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in sorted(os.listdir(folder)):  # Sort the filenames\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')  # Ensure image is in RGB\n",
    "            img_array = np.array(img)\n",
    "            # Pad the image\n",
    "            pad_width = ((0, 0), (0, target_size[1] - img_array.shape[1]), (0, 0))\n",
    "            padded_img = np.pad(img_array, pad_width, mode='constant', constant_values=0)\n",
    "            images.append(padded_img)\n",
    "            filenames.append(filename)\n",
    "    return np.array(images), filenames\n",
    "\n",
    "def load_and_pad_masks_from_folder(folder, target_size=(1024, 1536)):\n",
    "    masks = []\n",
    "    filenames = []\n",
    "    for filename in sorted(os.listdir(folder)):  # Sort the filenames\n",
    "        mask_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(mask_path):\n",
    "            mask = np.load(mask_path)\n",
    "            # Pad the mask\n",
    "            pad_width = ((0, 0), (0, target_size[1] - mask.shape[1]))\n",
    "            padded_mask = np.pad(mask, pad_width, mode='constant', constant_values=0)\n",
    "            masks.append(padded_mask)\n",
    "            filenames.append(filename)\n",
    "    return np.array(masks), filenames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Folder paths\n",
    "image_folder_path = r'/data1/sprasad/data/train/image3'\n",
    "mask_folder_path = r'/data1/sprasad/data/train/label3'\n",
    "\n",
    "# Load and pad images and masks\n",
    "large_images, image_filenames = load_and_pad_images_from_folder(image_folder_path)\n",
    "large_masks, mask_filenames = load_and_pad_masks_from_folder(mask_folder_path)\n",
    "\n",
    "# Ensure the filenames are sorted and correspond\n",
    "image_filenames = sorted(image_filenames)\n",
    "mask_filenames = sorted(mask_filenames)\n",
    "\n",
    "# Print shapes\n",
    "print(f'Shape of large_images: {large_images.shape}')  # Should be (18, 1024, 1536, 3)\n",
    "print(f'Shape of large_masks: {large_masks.shape}')    # Should be (18, 1024, 1536)\n",
    "\n",
    "# Desired patch size for smaller images and step size.\n",
    "patch_size = 256\n",
    "step = 256\n",
    "all_img_patches = []\n",
    "all_mask_patches = []\n",
    "all_patch_filenames = []\n",
    "\n",
    "for img_idx in range(large_images.shape[0]):\n",
    "    large_image = large_images[img_idx]\n",
    "    patches_img = patchify(large_image, (patch_size, patch_size, 3), step=step)  # Step=256 for 256 patches means no overlap\n",
    "\n",
    "    large_mask = large_masks[img_idx]\n",
    "    patches_mask = patchify(large_mask, (patch_size, patch_size), step=step)  # Step=256 for 256 patches means no overlap\n",
    "\n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            single_patch_img = patches_img[i, j, :, :, :]\n",
    "            single_patch_mask = patches_mask[i, j, :, :]\n",
    "\n",
    "            all_img_patches.append(single_patch_img)\n",
    "            all_mask_patches.append(single_patch_mask)\n",
    "\n",
    "            # Generate a patch filename for tracking\n",
    "            patch_filename = f\"{image_filenames[img_idx].split('.')[0]}_patch_{i}_{j}.npy\"\n",
    "            all_patch_filenames.append(patch_filename)\n",
    "\n",
    "images = np.array(all_img_patches)/255.0\n",
    "masks = np.array(all_mask_patches)\n",
    "\n",
    "# Create a list to store the indices of non-empty masks\n",
    "valid_indices = [i for i, mask in enumerate(masks) if mask.max() != 0]\n",
    "\n",
    "# Filter the image and mask arrays to keep only the non-empty pairs\n",
    "filtered_images = images[valid_indices]\n",
    "filtered_masks = masks[valid_indices]\n",
    "filtered_filenames = [all_patch_filenames[i] for i in valid_indices]\n",
    "\n",
    "print(\"Image shape:\", filtered_images.shape)  # e.g., (num_frames, height, width, num_channels)\n",
    "print(\"Mask shape:\", filtered_masks.shape)\n",
    "\n",
    "# Remove the extra dimension from images\n",
    "filtered_images = np.squeeze(filtered_images, axis=1)\n",
    "#filtered_images = filtered_images.astype(np.uint8)\n",
    "#filtered_masks = filtered_masks.astype(np.uint8)\n",
    "\n",
    "\n",
    "# # Convert the NumPy arrays to Pillow images and store them in a dictionary\n",
    "# dataset_dict = {\n",
    "#     \"image\": [Image.fromarray(img) for img in filtered_images],\n",
    "#     \"label\": [Image.fromarray(mask) for mask in filtered_masks],\n",
    "#     \"filename\": filtered_filenames\n",
    "# }\n",
    "\n",
    "\n",
    "# # Create the dataset using the datasets.Dataset class\n",
    "# dataset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sprasad/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "class SemanticSegmentationDataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            # Apply transformations\n",
    "            image = self.transform(image)\n",
    "            #mask = self.transform(mask)\n",
    "            mask=torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert images and masks to PyTorch tensors\n",
    "# filtered_images = torch.tensor(filtered_images, dtype=torch.float32).permute(0, 3, 1, 2)  # Convert to (N, C, H, W)\n",
    "# filtered_masks = torch.tensor(filtered_masks, dtype=torch.long)  # Masks typically have dtype long for segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing and transforming images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "train_dataset = SemanticSegmentationDataset(filtered_images, filtered_masks, transform=transform)\n",
    "test_dataset = SemanticSegmentationDataset(filtered_images, filtered_masks, transform=transform)  # Use separate data for testing in practice\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_images[0].transpose((0,1,2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,l in train_loader:\n",
    "    print(i.shape)\n",
    "    print(type(i))\n",
    "    i=i.squeeze(0)\n",
    "    print(i.shape)\n",
    "    i=i.permute(1,2,0)\n",
    "    l=l.permute(1,2,0)\n",
    "    print(i.shape)\n",
    "    i=std*i +mean\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(i)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(l, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "    print(type(i),type(l))\n",
    "\n",
    "    #print(np.min(i.numpy()))\n",
    "      \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = R2AttU_Net()\n",
    "model = model.to(device)\n",
    "sample_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Move the sample input to GPU if the model is on GPU\n",
    "sample_input = sample_input.to(device)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.logits = logits\n",
    "#         self.reduce = reduce\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         inputs=inputs.squeeze(1)\n",
    "#         if self.logits:\n",
    "#             BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "#         else:\n",
    "#             BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-BCE_loss)\n",
    "#         F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "#         if self.reduce:\n",
    "#             return torch.mean(F_loss)\n",
    "#         else:\n",
    "#             return F_loss\n",
    "\n",
    "# # Usage\n",
    "# criterion = FocalLoss(logits=True)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss with Logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(preds, targets, threshold=0.5):\n",
    "    preds = (preds > threshold).float()\n",
    "    preds = preds.bool()  # Convert to boolean for bitwise operations\n",
    "    targets = targets.bool()  # Convert to boolean for bitwise operations\n",
    "\n",
    "    intersection = (preds & targets).float().sum((1, 2))\n",
    "    union = (preds | targets).float().sum((1, 2))\n",
    "    iou = (intersection + 1e-10) / (union + 1e-10)  # avoid division by zero\n",
    "    return iou.mean()  # return mean IoU over the batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained For 92 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:26<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 67\n",
      "Mean loss: 0.0293\n",
      "Mean Jaccard Index: 0.6805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:24<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 68\n",
      "Mean loss: 0.0251\n",
      "Mean Jaccard Index: 0.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:22<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 69\n",
      "Mean loss: 0.0281\n",
      "Mean Jaccard Index: 0.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:23<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 70\n",
      "Mean loss: 0.0256\n",
      "Mean Jaccard Index: 0.7420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:25<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 71\n",
      "Mean loss: 0.0239\n",
      "Mean Jaccard Index: 0.7554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:24<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 72\n",
      "Mean loss: 0.0318\n",
      "Mean Jaccard Index: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:21<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 73\n",
      "Mean loss: 0.0365\n",
      "Mean Jaccard Index: 0.7722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:23<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 74\n",
      "Mean loss: 0.0236\n",
      "Mean Jaccard Index: 0.7723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:24<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 75\n",
      "Mean loss: 0.0208\n",
      "Mean Jaccard Index: 0.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:25<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 76\n",
      "Mean loss: 0.0198\n",
      "Mean Jaccard Index: 0.7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:30<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 77\n",
      "Mean loss: 0.0210\n",
      "Mean Jaccard Index: 0.7637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:31<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 78\n",
      "Mean loss: 0.0230\n",
      "Mean Jaccard Index: 0.7761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:22<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 79\n",
      "Mean loss: 0.0284\n",
      "Mean Jaccard Index: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:21<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 80\n",
      "Mean loss: 0.0219\n",
      "Mean Jaccard Index: 0.7695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:21<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 81\n",
      "Mean loss: 0.0191\n",
      "Mean Jaccard Index: 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:22<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 82\n",
      "Mean loss: 0.0176\n",
      "Mean Jaccard Index: 0.7791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:21<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 83\n",
      "Mean loss: 0.0209\n",
      "Mean Jaccard Index: 0.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:23<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 84\n",
      "Mean loss: 0.0382\n",
      "Mean Jaccard Index: 0.7545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:24<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 85\n",
      "Mean loss: 0.0231\n",
      "Mean Jaccard Index: 0.7081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:21<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 86\n",
      "Mean loss: 0.0173\n",
      "Mean Jaccard Index: 0.7680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:22<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 87\n",
      "Mean loss: 0.0170\n",
      "Mean Jaccard Index: 0.7863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:22<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 88\n",
      "Mean loss: 0.0167\n",
      "Mean Jaccard Index: 0.7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:25<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 89\n",
      "Mean loss: 0.0179\n",
      "Mean Jaccard Index: 0.7324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:28<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 90\n",
      "Mean loss: 0.0176\n",
      "Mean Jaccard Index: 0.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:19<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 91\n",
      "Mean loss: 0.0173\n",
      "Mean Jaccard Index: 0.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:19<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 92\n",
      "Mean loss: 0.0176\n",
      "Mean Jaccard Index: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:19<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 93\n",
      "Mean loss: 0.0168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m val_images \u001b[38;5;241m=\u001b[39m val_images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     55\u001b[0m val_masks \u001b[38;5;241m=\u001b[39m val_masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 57\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(val_outputs)  \u001b[38;5;66;03m# Apply sigmoid if the model does not include it\u001b[39;00m\n\u001b[1;32m     60\u001b[0m iou \u001b[38;5;241m=\u001b[39m jaccard_index(val_outputs, val_masks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data1/sprasad/attntnadvUnet/attentionR2u/network.py:216\u001b[0m, in \u001b[0;36mR2AttU_Net.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAtt3(g\u001b[38;5;241m=\u001b[39md3,x\u001b[38;5;241m=\u001b[39mx2)\n\u001b[1;32m    215\u001b[0m d3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x2,d3),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m d3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUp_RRCNN3\u001b[49m\u001b[43m(\u001b[49m\u001b[43md3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUp2(d3)\n\u001b[1;32m    219\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAtt2(g\u001b[38;5;241m=\u001b[39md2,x\u001b[38;5;241m=\u001b[39mx1)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data1/sprasad/attntnadvUnet/attentionR2u/network.py:99\u001b[0m, in \u001b[0;36mRRCNN_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 99\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv_1x1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRCNN(x)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m+\u001b[39mx1\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the directory to save the model weights\n",
    "model.load_state_dict(torch.load('/data1/sprasad/attntnadvUnet/attentionR2u/weights3/model_epoch_66.pth'))\n",
    "save_dir = '/data1/sprasad/attntnadvUnet/attentionR2u/weights3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 133\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for images, masks in tqdm(train_loader):\n",
    "        # Move images and masks to device\n",
    "        images=images.float()\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        masks = masks.float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        outputs=outputs.squeeze(1)\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    # Save model after each epoch\n",
    "    save_path = os.path.join(save_dir, f'model_epoch_{epoch+67}.pth')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # Compute mean loss for the epoch\n",
    "    mean_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f'EPOCH: {epoch+67}')\n",
    "    print(f'Mean loss: {mean_loss:.4f}')\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        iou_scores = []\n",
    "        for val_images, val_masks in test_loader:\n",
    "            val_images=val_images.float()\n",
    "            val_images = val_images.to(device)\n",
    "            val_masks = val_masks.to(device)\n",
    "\n",
    "            val_outputs = model(val_images)\n",
    "            val_outputs = torch.sigmoid(val_outputs)  # Apply sigmoid if the model does not include it\n",
    "\n",
    "            iou = jaccard_index(val_outputs, val_masks)\n",
    "            iou_scores.append(iou.cpu().numpy()) \n",
    "\n",
    "        mean_iou = np.mean(iou_scores)\n",
    "        print(f'Mean Jaccard Index: {mean_iou:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
